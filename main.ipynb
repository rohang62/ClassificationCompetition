{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/rohangoel66/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import dataextraction as de\n",
    "from bs4 import BeautifulSoup\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "import re,string,unicodedata\n",
    "from string import punctuation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "Tesla K80\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = de.extract_data('data/train.jsonl')\n",
    "train = de.parse_json(data, True)\n",
    "\n",
    "data = de.extract_data('data/test.jsonl')\n",
    "test = de.parse_json(data, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000\n",
      "1800\n"
     ]
    }
   ],
   "source": [
    "print(len(train.index))\n",
    "print(len(test.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = set(stopwords.words('english'))\n",
    "punctuation = list(string.punctuation)\n",
    "stop.update(punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_html(text):\n",
    "    soup = BeautifulSoup(text, \"html.parser\")\n",
    "    return soup.get_text()\n",
    "\n",
    "def remove_between_square_brackets(text):\n",
    "    return re.sub('\\[[^]]*\\]', '', text)\n",
    "\n",
    "def remove_between_square_brackets(text):\n",
    "    return re.sub(r'http\\S+', '', text)\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    final_text = []\n",
    "    for i in text.split():\n",
    "        if i.strip().lower() not in stop and i != \"@USER\":\n",
    "            final_text.append(i.strip().lower())\n",
    "    return \" \".join(final_text)\n",
    "\n",
    "def denoise_text(text):\n",
    "    text = strip_html(text)\n",
    "    text = remove_between_square_brackets(text)\n",
    "    text = remove_stopwords(text)\n",
    "    return text\n",
    "\n",
    "train['response']=train['response'].apply(denoise_text)\n",
    "test['response']=test['response'].apply(denoise_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SARCASM</td>\n",
       "      <td>get .. obviously care would've moved right alo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SARCASM</td>\n",
       "      <td>trying protest talking labels label wtf make em</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SARCASM</td>\n",
       "      <td>makes insane money movies einstein #learnhowth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SARCASM</td>\n",
       "      <td>meanwhile trump even release sat scores wharto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SARCASM</td>\n",
       "      <td>pretty sure anti-lincoln crowd claimed democra...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     label                                           response\n",
       "0  SARCASM  get .. obviously care would've moved right alo...\n",
       "0  SARCASM    trying protest talking labels label wtf make em\n",
       "0  SARCASM  makes insane money movies einstein #learnhowth...\n",
       "0  SARCASM  meanwhile trump even release sat scores wharto...\n",
       "0  SARCASM  pretty sure anti-lincoln crowd claimed democra..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import torch\n",
    "import transformers as ppb\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.replace(\"SARCASM\", 1)\n",
    "train = train.replace(\"NOT_SARCASM\", 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_class, tokenizer_class, pretrained_weights = (ppb.DistilBertModel, ppb.DistilBertTokenizer, 'distilbert-base-uncased')\n",
    "tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n",
    "model = model_class.from_pretrained(pretrained_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized = train['response'].apply((lambda x: tokenizer.encode(x, add_special_tokens=True, max_length = 512, truncation = True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 0\n",
    "for i in tokenized.values:\n",
    "    if len(i) > max_len:\n",
    "        max_len = len(i)\n",
    "\n",
    "padded = np.array([i + [0]*(max_len-len(i)) for i in tokenized.values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 73)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_mask = np.where(padded != 0, 1, 0)\n",
    "attention_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = torch.tensor(padded)\n",
    "attention_mask = torch.tensor(attention_mask)\n",
    "\n",
    "with torch.no_grad():\n",
    "    last_hidden_states = model(input_ids, attention_mask=attention_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = last_hidden_states[0][:,0,:].numpy()\n",
    "train_labels = train['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized = test['response'].apply((lambda x: tokenizer.encode(x, add_special_tokens=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 0\n",
    "for i in tokenized.values:\n",
    "    if len(i) > max_len:\n",
    "        max_len = len(i)\n",
    "\n",
    "padded = np.array([i + [0]*(max_len-len(i)) for i in tokenized.values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1800, 49)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_mask = np.where(padded != 0, 1, 0)\n",
    "attention_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = torch.tensor(padded)  \n",
    "attention_mask = torch.tensor(attention_mask)\n",
    "\n",
    "with torch.no_grad():\n",
    "    last_hidden_states = model(input_ids, attention_mask=attention_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=10000)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_clf = LogisticRegression(max_iter = 10000)\n",
    "lr_clf.fit(train_features, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8122"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_clf.score(train_features, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features = last_hidden_states[0][:,0,:].numpy()\n",
    "test_pred = lr_clf.predict(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import savetxt\n",
    "savetxt('train_features.csv', train_features, delimiter=',')\n",
    "savetxt('train_labelst.csv', train_labels.to_numpy(), delimiter=',')\n",
    "savetxt('test_features.csv', test_features, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768\n",
      "768\n"
     ]
    }
   ],
   "source": [
    "print(train_features.shape[1])\n",
    "print(test_features.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import loadtxt\n",
    "loadtxt('train_features.csv', delimiter=',')\n",
    "loadtxt('train_labels.csv', delimiter=',')\n",
    "loadtxt('test_featurest.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, n_features):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(n_features, 256)\n",
    "        self.fc2 = nn.Linear(256, 80)\n",
    "        self.fc3 = nn.Linear(80, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return torch.sigmoid(self.fc3(x))\n",
    "\n",
    "\n",
    "net = Net(train_features.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = list(net.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.from_numpy(train_features).float()\n",
    "y_train = torch.squeeze(torch.from_numpy(train_labels.to_numpy()).float())\n",
    "X_test = torch.from_numpy(test_features).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer = optim.Adam(net.parameters(), lr=0.001, weight_decay = 0.05)\n",
    "optimizer = optim.AdamW(params, lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0.01, amsgrad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "X_train = X_train.to(device)\n",
    "y_train = y_train.to(device)\n",
    "X_val = X_val.to(device)\n",
    "y_val = y_val.to(device)\n",
    "X_test = X_test.to(device)\n",
    "net = net.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(y_true, y_pred):\n",
    "    predicted = y_pred.ge(.5).view(-1)\n",
    "    return (y_true == predicted).sum().float() / len(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 20 Train set - loss: 0.334, \n",
      "        accuracy: 0.845\n",
      "        Val set - loss: 0.555, \n",
      "        accuracy: 0.745\n",
      "epoch 40 Train set - loss: 0.135, \n",
      "        accuracy: 0.928\n",
      "        Val set - loss: 0.823, \n",
      "        accuracy: 0.729\n",
      "epoch 60 Train set - loss: 0.111, \n",
      "        accuracy: 0.975\n",
      "        Val set - loss: 1.196, \n",
      "        accuracy: 0.743\n",
      "epoch 80 Train set - loss: 0.009, \n",
      "        accuracy: 0.999\n",
      "        Val set - loss: 2.352, \n",
      "        accuracy: 0.734\n",
      "epoch 100 Train set - loss: 0.004, \n",
      "        accuracy: 0.999\n",
      "        Val set - loss: 2.822, \n",
      "        accuracy: 0.732\n",
      "epoch 120 Train set - loss: 0.001, \n",
      "        accuracy: 1.0\n",
      "        Val set - loss: 3.262, \n",
      "        accuracy: 0.735\n",
      "epoch 140 Train set - loss: 0.0, \n",
      "        accuracy: 1.0\n",
      "        Val set - loss: 3.443, \n",
      "        accuracy: 0.735\n",
      "epoch 160 Train set - loss: 0.015, \n",
      "        accuracy: 0.999\n",
      "        Val set - loss: 2.145, \n",
      "        accuracy: 0.728\n",
      "epoch 180 Train set - loss: 0.001, \n",
      "        accuracy: 1.0\n",
      "        Val set - loss: 3.229, \n",
      "        accuracy: 0.735\n",
      "epoch 200 Train set - loss: 0.001, \n",
      "        accuracy: 1.0\n",
      "        Val set - loss: 3.718, \n",
      "        accuracy: 0.737\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "epochs = 100\n",
    "batch_size = 50\n",
    "num_batches = X_train.shape[0] // batch_size\n",
    "def round_tensor(t, decimal_places=3):\n",
    "    return round(t.item(), decimal_places)\n",
    "for epoch in range(1, epochs + 1):\n",
    "    epoch_loss = 0\n",
    "    for batch in range(num_batches):\n",
    "        batch_x = X_train[batch * batch_size: batch * batch_size + batch_size]\n",
    "        batch_y = y_train[batch * batch_size: batch * batch_size + batch_size]\n",
    "        y_pred = net(batch_x)\n",
    "        y_pred = torch.squeeze(y_pred)\n",
    "        train_loss = criterion(y_pred, batch_y)\n",
    "        epoch_loss += train_loss\n",
    "        optimizer.zero_grad()\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "    if epoch % (epochs / 10) == 0:\n",
    "        y_pred = net(X_train)\n",
    "        y_pred = torch.squeeze(y_pred)\n",
    "        epoch_acc = calculate_accuracy(y_train, y_pred)\n",
    "        y_val_pred = net(X_val)\n",
    "        y_val_pred = torch.squeeze(y_val_pred)\n",
    "        val_loss = criterion(y_val_pred, y_val)\n",
    "        val_predicted = y_val_pred.ge(.5).view(-1)\n",
    "        val_acc = calculate_accuracy(y_val, y_val_pred)\n",
    "        print(f'''epoch {epoch} Train set - loss: {round_tensor(epoch_loss / num_batches)}, \n",
    "        accuracy: {round_tensor(epoch_acc)}\n",
    "        Val set - loss: {round_tensor(val_loss)}, \n",
    "        accuracy: {round_tensor(val_acc)}''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.5949e-09],\n",
      "        [1.0000e+00],\n",
      "        [9.8934e-01],\n",
      "        ...,\n",
      "        [1.5654e-01],\n",
      "        [6.8816e-03],\n",
      "        [7.7374e-05]], grad_fn=<SigmoidBackward>)\n"
     ]
    }
   ],
   "source": [
    "y_test = net(X_test)\n",
    "print(y_test)\n",
    "y_labels = []\n",
    "for i in range(y_test.shape[0]):\n",
    "    if y_test[i] < 0.5:\n",
    "        y_labels.append(\"NOT_SARCASM\")\n",
    "    else:\n",
    "        y_labels.append(\"SARCASM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('answer.txt', 'w') as f:\n",
    "    for tid, pred in zip(test['id'], y_labels):\n",
    "        f.writelines(f'{tid},{pred}\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
